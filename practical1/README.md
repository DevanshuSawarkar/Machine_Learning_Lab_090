# ğŸ“˜ Machine Learning Practical 1 â€“ Linear Regression

## ğŸ‘¨â€ğŸ“ Student Details
- **Name**: Devanshu Sawarkar  
- **PRN**: 22070521090  
- **Section**: C  
- **Subject**: Machine Learning Laboratory  
- **Practical Number**: 1  
- **Topic**: Simple and Multiple Linear Regression  

---

## âœ… Aim
To implement Simple Linear Regression and Multiple Linear Regression using Python and evaluate their performance on a real-world dataset.

---

## ğŸ“‚ Dataset Details
- **Dataset Name**: Students Performance in Exams  
- **Source**: Kaggle  

---

## ğŸ”¬ Tools & Technologies Used
- Python  
- Jupyter Notebook  
- Libraries:  
  - pandas  
  - matplotlib  
  - seaborn  
  - sklearn (scikit-learn)  

---

## ğŸ§ª Practical Work

### ğŸ“Œ Part A: Simple Linear Regression
- **Objective**: Predict *writing score* based on *reading score*
- **Procedure**:
  - Data loading and preprocessing
  - Feature selection
  - Train-test split
  - Model training using `LinearRegression`
  - Prediction and evaluation using:
    - Mean Squared Error (MSE)
    - RÂ² Score
  - Plotting regression line for visualization

### ğŸ“Œ Part B: Multiple Linear Regression
- **Objective**: Predict *math score* based on *reading score*, and *writing score*
- **Procedure**:
  - Train-test split
  - Model training and prediction
  - Evaluation of model performance

---

## ğŸ“ˆ Sample Output (Evaluation Metrics)
```
Mean Squared Error: 23.870380714185085
RÂ² Score: 0.9009597530871629
```

---

## ğŸ“Š Graphical Representation
- Scatter plot showing actual vs predicted scores
- Regression line for visual evaluation

---

## ğŸ“ Instructions to Run
1. Open the `.ipynb` file in Jupyter Notebook.
2. Ensure the dataset path is correct.
3. Run all cells sequentially.
4. Observe outputs and graphs.

---

## âœ… Conclusion
The implementation successfully demonstrates how to apply Linear Regression techniques using scikit-learn. The models showed a good fit and were evaluated using appropriate metrics and visualizations.

---
